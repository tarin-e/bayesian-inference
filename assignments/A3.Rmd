## Assignment 3

### 1a,b) a) Implement the priors for the three parameters in JAGS. Implement the likelihood in JAGS. Hint: JAGS provides the step() function which returns 0 if the argument is negative and 1 otherwise.

Loading coal dataset

```{r}
library("rjags")

data = data.frame(t=c(1851, 1852, 1853, 1854, 1855, 1856, 1857,
                      1858, 1859, 1860, 1861, 1862, 1863, 1864,
                      1865, 1866, 1867, 1868, 1869, 1870, 1871,
                      1872, 1873, 1874, 1875, 1876, 1877, 1878,
                      1879, 1880, 1881, 1882, 1883, 1884, 1885,
                      1886, 1887, 1888, 1889, 1890, 1891, 1892,
                      1893, 1894, 1895, 1896, 1897, 1898, 1899,
                      1900, 1901, 1902, 1903, 1904, 1905, 1906,
                      1907, 1908, 1909, 1910, 1911, 1912, 1913,
                      1914, 1915, 1916, 1917, 1918, 1919, 1920,
                      1921, 1922, 1923, 1924, 1925, 1926, 1927,
                      1928, 1929, 1930, 1931, 1932, 1933, 1934, 
                      1935, 1936, 1937, 1938, 1939, 1940, 1941,
                      1942, 1943, 1944, 1945, 1946, 1947, 1948,
                      1949, 1950, 1951, 1952, 1953, 1954, 1955,
                      1956, 1957, 1958, 1959, 1960, 1961, 1962),
            y=c(4, 5, 4, 1, 0, 4, 3, 4, 0, 6, 3, 3, 4, 0,
                      2, 6, 3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5,
                      3, 4, 2, 5, 2, 2, 3, 4, 2, 1, 3, 2, 2, 1,
                      1, 1, 1, 3, 0, 0, 1, 0, 1, 1, 0, 0, 3, 1,
                      0, 3, 2, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,
                      0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 3, 3, 1, 1,
                      2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 0, 1, 4, 0,
                      0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1))
```

```{r}
model = "model
{
  # priors
  lambda_1 ~ dunif(0, 10)
  lambda_2 ~ dunif(0, 10)
  t_c ~ dunif(1851, 1962)
  
  # likelihood
  for(i in 1:length(y))
  {
    y[i] ~ dpois(ifelse(step(t_c - t[i]), lambda_1, lambda_2))
  }
  
  # prediction node
  t_new <- 1963
  y_new ~ dpois(ifelse(step(t_c - t_new), lambda_1, lambda_2))
}
"
```

Plotting data to know what I'm looking at.

```{r}
plot(data$t, data$y, xlab = "t", ylab = "y")
```


Running JAGS.

```{r}
# Variables to monitor
variable_names = c("lambda_1", "lambda_2", "t_c", "y_new")

# How many proper steps?
steps = 100000

# Thinning?
thin = 10

# Create a JAGS model object
jm = jags.model(textConnection(model), data)

# Do some MCMC
results = coda.samples(jm, variable_names, steps, thin=thin)

# Extract chains as data frame
results = as.data.frame(results[[1]])
```

```{r}
plot(results)
```
Appears uncorrelated, great!

### 1c) ompute credible intervals for the three parameters.

lambda_1

```{r}
lambda_1_sorted = sort(results$lambda_1)
l = length(lambda_1_sorted)
c(lambda_1_sorted[0.025*l], lambda_1_sorted[0.975*l])
```

lambda_2

```{r}
lambda_2_sorted = sort(results$lambda_2)
l = length(lambda_2_sorted)
c(lambda_2_sorted[0.025*l], lambda_2_sorted[0.975*l])
```

t_c

```{r}
t_c_sorted = sort(results$t_c)
l = length(t_c_sorted)
c(t_c_sorted[0.025*l], t_c_sorted[0.975*l])
```

### 1d) Plot the data with regression curves sampled from the posterior distribution going
through it.

```{r}
{
plot(data$t, data$y)

# plot lines
for (i in 1:1000) {
  # wtf is a poisson, help pls!!!
  lines(x = data$x, y = exp(-results$lambda_1[i]) * results$lambda_1[i]^data$x / factorial(data$x), col = rgb(0, 0, 1, alpha = 0.05))
}
}
```

### 1e) Add a node to the model to predict the number of deaths in 1963, and find the
probability that this is three or more.

```{r}
hist(results$y_new, breaks = 100)
```
```{r}
prob <- sum(results$y_new >= 3) / length(results$y_new)
prob
```

0.0736 probability that there are 3 or more deaths in 1963.

### 2a) Draw a PGM for the simple model and a PGM for the hierarchical model. For the
latter, I don’t mind whether you explicitly include the deterministic nodes, or merge sigma and
log_sigma into one node for presentation purposes.

```{r}
# inselt .png here
```

### 2b) Run the simple model for a lot of iterations and obtain the posterior distribution for
the true log-mass of the first black hole. Summarise it using the posterior mean ± the posterior
standard deviation, which for a normal posterior is a 68% central credible interval. The result
should be obvious in hindsight.

```{r}
black_holes_data = read.csv("../data/black_hole_masses.csv")

simple_model = "model {
  # Casual wide prior for each true mass
  for(i in 1:length(measurement))
  {
    true_mass[i] ~ dnorm(0, 1/1000^2)
    measurement[i] ~ dnorm(true_mass[i], 1/stdev[i]^2)
  }
}"

hier_model = "model {
  # Casual wide priors now apply to the hyperparameters
  mu ~ dnorm(0, 1/1000^2)
  log_sigma ~ dnorm(0, 1/10^2)
  sigma <- exp(log_sigma)
  for(i in 1:length(measurement))
  {
    true_mass[i] ~ dnorm(mu, 1/sigma^2)
    measurement[i] ~ dnorm(true_mass[i], 1/stdev[i]^2)
  }
}"
```

Simple Model (Non-Hierarchical)

```{r}
# Variables to monitor
variable_names_simple = c("true_mass")

# How many proper steps?
steps = 100000

# Thinning?
thin = 10

# Create a JAGS model object
jm_simple = jags.model(textConnection(simple_model), black_holes_data)

# Do some MCMC
results_simple = coda.samples(jm_simple, variable_names_simple, steps, thin=thin)

# Extract chains as data frame
results_simple = as.data.frame(results_simple[[1]])
```

Posterior Distribution of true_mass of first observation

```{r}
# first method for calculating mean and std
true_mass_1_mean = mean(results_simple$`true_mass[1]`)
true_mass_1_std = sd(results_simple$`true_mass[1]`)

# second method for calculating mean and std
# true_mass_1_sorted = sort(results_simple$`true_mass[1]`)
# l = length(true_mass_1_sorted)
# c(true_mass_1_sorted[0.26*l], true_mass_1_sorted[0.5*l], true_mass_1_sorted[0.84*l])

print(paste("True Mass of First Black Hole - Mean:", true_mass_1_mean, 
                ", +- Standard Deviation:", true_mass_1_std))
```

```{r}
hist_results <- hist(results_simple$`true_mass[1]`, breaks = 100)

breaks <- hist_results$breaks
colors <- ifelse(breaks >= (true_mass_1_mean - true_mass_1_std) & breaks <= (true_mass_1_mean + true_mass_1_std), "red", "skyblue")

hist(results_simple$`true_mass[1]`, breaks = 100, main = "Histogram of True Mass of First Black Hole", 
     xlab = "True Mass of First Black Hole", ylab = "Frequency", col = colors)
```

Appears roughly normally distributed

Hierarchical Model

```{r}
# Variables to monitor
variable_names_hier = c("mu", "sigma", "true_mass")

# How many proper steps?
steps = 100000

# Thinning?
thin = 10

# Create a JAGS model object
jm_hier = jags.model(textConnection(hier_model), black_holes_data)

# Do some MCMC
results_hier = coda.samples(jm_hier, variable_names_hier, steps, thin=thin)

# Extract chains as data frame
results_hier = as.data.frame(results_hier[[1]])
```

