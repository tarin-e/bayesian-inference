### 1a) Do the exercise I posed in the lecture slides, to re-write the model so that the parameters
are the logits ℓi = log (θi/(1 − θi)), and that it the prior for the logits that is normal (given
the hyperparameters):

ℓi | μ, σ ∼ Normal μ, σ2.

Take care to assign sane priors to μ and σ.

```{r}
kobe_data = read.csv("../data/kobe_bryant.csv")

model = "model {
  mu ~ dnorm(0, 1/3^2)
  sigma ~ dnorm(0, 1)T(0, )
  for(i in 1:length(successes))
  {
    logit[i] ~ dnorm(mu, 1/sigma^2)
    theta[i] <- 1/(1 + exp(-logit[i]))
    successes[i] ~ dbin(theta[i], attempts[i])
  }
}"
```


```{r}
# variables to monitor
variable_names = c("mu", "sigma", "logit", "theta")

# How many proper steps?
steps = 100000

# Thinning?
thin = 10

# Import the rjags library
library("rjags")

# Create a JAGS model object
jm = jags.model(textConnection(model), kobe_data)

# Do some MCMC
results = coda.samples(jm, variable_names, steps, thin=thin)

# Extract chains as data frame
results = as.data.frame(results[[1]])
```


```{r}
hist(results$mu, breaks = 100)
hist(results$sigma, breaks = 100)
```

Looking at only season 1 and season 17. Compare credible intervals.

```{r}
sorted = sort(results$`theta[1]`)
l = length(sorted)
cred = c(sorted[0.025*l], sorted[0.975*l])

hist_results <- hist(results$`theta[1]`, breaks = 100)

breaks <- hist_results$breaks
colors <- ifelse(breaks >= cred[1] & breaks <= cred[2], "red", "skyblue")

hist(results$`theta[1]`, breaks = 100, main = "Histogram of theta[1]", 
     xlab = "Theta[1]", ylab = "Frequency", col = colors)
```

```{r}
cred
```


```{r}
sorted = sort(results$`theta[17]`)
l = length(sorted)
cred = c(sorted[0.025*l], sorted[0.975*l])

hist_results <- hist(results$`theta[17]`, breaks = 100)

breaks <- hist_results$breaks
colors <- ifelse(breaks >= cred[1] & breaks <= cred[2], "red", "skyblue")

hist(results$`theta[17]`, breaks = 100, main = "Histogram of theta[1]", 
     xlab = "Theta[1]", ylab = "Frequency", col = colors)
```

```{r}
cred
```

### 1b) Add a node to the model to generate from the posterior predictive distribution for the
number of successes xnew in a hypothetical (impossible) 100 ‘next’ NBA field goal attempts
by Kobe Bryant, and plot the posterior predictive distribution for xnew.
2The absence of a second value in the truncation notation means that the distribution is only truncated on
the left.

```{r}
model = "model {
  mu ~ dnorm(0, 1/3^2)
  sigma ~ dnorm(0, 1)T(0, )
  for(i in 1:length(successes))
  {
    logit[i] ~ dnorm(mu, 1/sigma^2)
    theta[i] <- 1/(1 + exp(-logit[i]))
    successes[i] ~ dbin(theta[i], attempts[i])
  }
  
  logit_new ~ dnorm(mu, 1/sigma^2)
  theta_new <- 1/(1 + exp(-logit_new))
  attempts_new <- 100
  successes_new ~ dbin(theta_new, attempts_new)
}"
```

```{r}
# variables to monitor
variable_names = c("mu", "sigma", "logit", "theta", "successes_new")

# How many proper steps?
steps = 100000

# Thinning?
thin = 10

# Import the rjags library
library("rjags")

# Create a JAGS model object
jm = jags.model(textConnection(model), kobe_data)

# Do some MCMC
results = coda.samples(jm, variable_names, steps, thin=thin)

# Extract chains as data frame
results = as.data.frame(results[[1]])
```

```{r}
sorted = sort(results$successes_new)
l = length(sorted)
cred = c(sorted[0.025*l], sorted[0.975*l])

hist_results <- hist(results$successes_new, breaks = 100)

breaks <- hist_results$breaks
colors <- ifelse(breaks >= cred[1] & breaks <= cred[2], "red", "skyblue")

hist(results$successes_new, breaks = 100, main = "Histogram of 100 new attempts", 
     xlab = "Theta[1]", ylab = "Frequency", col = colors)
```

